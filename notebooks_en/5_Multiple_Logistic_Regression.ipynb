{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Content under Creative Commons Attribution license CC-BY 4.0, code under BSD 3-Clause License © 2021 Lorena A. Barba, Pi-Yueh Chuang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple logistic regression\n",
    "\n",
    "This is the fifth lesson of our module on _deep learning_, and it's perhpas surprising that we still are discussing linear models! Our approach is to build up to our final goal in an incremental fashion. \n",
    "We have thus stayed in the more accessible setting of linear models while introducing key ingredients: gradient descent for optimization; automatic differentiation; multi-dimensional input variables (features); normalization (feature scaling); underfitting/overfitting and regularization. You've come a long way!\n",
    "\n",
    "In this lesson, we want to give you a taste of more practical machine learning applications. We are going to use _multiple logistic regression_ (meaning, we have multiple features) for the problem of identifying defective metal-casting parts: a classification problem. Let's begin. \n",
    "\n",
    "First, let's import modules that we'll need later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import numpy\n",
    "from autograd import grad\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `numpy` submodule from `autograd` is used instead of regular `numpy` so that we can do automatic differentiation with the `grad` function. \n",
    "This is where `autograd` keeps track of and applies the differentiation rules to NumPy functions. The only requirement is that we define Python _functions_ for the code portions we would like derivatives of. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images of metal-casting parts\n",
    "\n",
    "In automated manufacturing, it's common to check the quality of products using computer vision. After taking a picture of a product, a machine learning model identifies if this product has defects or not. This lesson will use a multiple logistic regression model to identify defective metal-casting parts from pictures.\n",
    "\n",
    "The source of the images of casting parts is in Reference [1]. To make the dataset smaller for this teaching material, we converted the images to grayscale and reduced the resolutions and the number of images. (With the original data, the training would take too long to run on a laptop.) We have also transformed the data to `numpy` compressed array format (extension `.npz`). This file format is useful for saving several arrays together in one file. \n",
    "Read about it in the [`numpy.savez()`](https://numpy.org/doc/stable/reference/generated/numpy.savez.html) documentation page.\n",
    "\n",
    "Run the code below to load the image data. If you don't have the data locally, you can download it from this short URL: https://go.gwu.edu/engcomp6data5 — be sure to edit the path below, in that case. Be sure to read the documentation page for [`numpy.load()`](https://numpy.org/doc/stable/reference/generated/numpy.load.html#numpy.load) if you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in images and labels\n",
    "with numpy.load(\"../data/casting_images.npz\") as data:\n",
    "    ok_images = data[\"ok_images\"]\n",
    "    def_images = data[\"def_images\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ok_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data file contains two datasets: `ok_images` and `def_images`, representing the images of casting parts looking okay and defective. Each dataset has a shape of `(number of images, total number of pixels)`.\n",
    "\n",
    "You may wonder why we have the ***total number of pixels*** rather than ***pixels in x by pixels in y***. Originally, a grayscale image is a 2D array with each element representing the color value of the corresponding pixel. Instead of 2D arrays, we use 1D arrays (i.e., flattened) here. Using 1D arrays makes programming easier because we can use basic linear algebra (such as matrix-vector multiplications) to express and code our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do whenever obtaining a dataset is to examine the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ok_total = ok_images.shape[0]\n",
    "res = int(numpy.sqrt(def_images.shape[1]))\n",
    "\n",
    "print(\"Number of images without defects:\", n_ok_total)\n",
    "print(\"Image resolution: {} by {}\".format(res, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_def_total = def_images.shape[0]\n",
    "print(\"Number of images with defects:\", n_def_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not check whether the images in `def_images` have the same resolution as those in `ok_images` because we are pretty sure they do. However, as this is your first time seeing the dataset, it's never a bad idea to do a double-check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `pyplot.imshow` to examine the images. Don't forget to convert the flattened image arrays back to 2D arrays before plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = pyplot.subplots(2, 3, figsize=(8, 6), tight_layout=True)\n",
    "axes[0, 0].imshow(ok_images[0].reshape((res, res)), cmap=\"gray\")\n",
    "axes[0, 1].imshow(ok_images[50].reshape((res, res)), cmap=\"gray\")\n",
    "axes[0, 2].imshow(ok_images[100].reshape((res, res)), cmap=\"gray\")\n",
    "axes[1, 0].imshow(ok_images[150].reshape((res, res)), cmap=\"gray\")\n",
    "axes[1, 1].imshow(ok_images[200].reshape((res, res)), cmap=\"gray\")\n",
    "axes[1, 2].imshow(ok_images[250].reshape((res, res)), cmap=\"gray\")\n",
    "fig.suptitle(\"Casting parts without defects\", fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And some images of the casting parts with defects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = pyplot.subplots(2, 3, figsize=(8, 6), tight_layout=True)\n",
    "axes[0, 0].imshow(def_images[0].reshape((res, res)), cmap=\"gray\")\n",
    "axes[0, 1].imshow(def_images[50].reshape((res, res)), cmap=\"gray\")\n",
    "axes[0, 2].imshow(def_images[100].reshape((res, res)), cmap=\"gray\")\n",
    "axes[1, 0].imshow(def_images[150].reshape((res, res)), cmap=\"gray\")\n",
    "axes[1, 1].imshow(def_images[200].reshape((res, res)), cmap=\"gray\")\n",
    "axes[1, 2].imshow(def_images[250].reshape((res, res)), cmap=\"gray\")\n",
    "fig.suptitle(\"Casting parts with defects\", fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple logistic regression\n",
    "\n",
    "Lesson 2 introduced you to logistic regression for binary classification based on a single feature. A logistic regression model can also be used to predict the probability of a multi-dimensional input (e.g., an image) being of class $1$ or $0$.\n",
    "\n",
    "The numbers $1$ and $0$ represent digitized labels, classes, or categories. Humans naturally use strings to label or categorize things. Computationally, it is easier to use numbers to describe categories. In this lesson, we will use $1$ to represent defective casting parts and $0$ for normal parts. Our logistic model aims to predict the probability of a casting part being defective.\n",
    "\n",
    "The only difference between this lesson and lesson 2 is the number of input features. You have seen multiple linear regression in lesson 3: the setting is similar here. If we have $N$ images during training, our model is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{y}^{(1)} &= \\operatorname{logistic}\\left(b + w_1 x_1^{(1)} + w_2 x_2^{(1)} + \\cdots + w_{n} x_{n}^{(1)}\\right) \\\\\n",
    "\\hat{y}^{(2)} &= \\operatorname{logistic}\\left(b + w_1 x_1^{(2)} + w_2 x_2^{(2)} + \\cdots + w_{n} x_{n}^{(2)}\\right) \\\\\n",
    "\\vdots & \\\\\n",
    "\\hat{y}^{(N)} &= \\operatorname{logistic}\\left(b + w_1 x_1^{(N)} + w_2 x_2^{(N)} + \\cdots + w_{n} x_{n}^{(N)}\\right) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where the superscripts $(1)\\dots(N)$ denote the $N$ images; $\\hat{y}$ is the predicted probability of the corresponding image being defective; and $x_1, x_2, \\dots, x_{n}$ represent the greyscale values for the $n$ pixels.\n",
    "\n",
    "In matrix-vector form:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\\hat{y}^{(1)} \\\\ \\vdots \\\\ \\hat{y}^{(N)}\\end{bmatrix} =\n",
    "\\operatorname{logistic}\\left(\n",
    "b + \n",
    "\\begin{bmatrix}\n",
    "x_1^{(1)} & \\cdots & x_{n_{pixels}}^{(1)} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "x_1^{(N)} & \\cdots & x_{n_{pixels}}^{(N)}\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}w_1 \\\\ \\vdots \\\\ w_{n_{pixels}} \\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{y}}  = \n",
    "\\operatorname{logistic}\\left(b + X\\cdot \\mathbf{w}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the logistic function is the same as in lesson 2, but now it also works with an array input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    \"\"\"Logistic/sigmoid function.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    x : numpy.ndarray\n",
    "        The input to the logistic function.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The output.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The function does not restrict the shape of the input array. The output\n",
    "    has the same shape with the input.\n",
    "    \"\"\"\n",
    "    return 1. / (1. + numpy.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our multiple logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_model(x, params):\n",
    "    \"\"\"A logistic regression model.\n",
    "    \n",
    "    A a logistic regression is y = sigmoid(x * A + b), where the operator *\n",
    "    denotes a mat-vec multiplication.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    x : numpy.ndarray\n",
    "        The input of the model. The shape should be (n_images, n_total_pixels).\n",
    "    params : a tuple/list of two elements\n",
    "        The first element is a 2D array with shape (n_total_pixels, 1). The\n",
    "        second elenment is a scalar.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    probabilities : numpy.ndarray\n",
    "        The output is a 1D array with length n_samples.\n",
    "    \"\"\"\n",
    "    return logistic(numpy.dot(x, params[0])+params[1]).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function is also the same as in lesson 2 for regular logistic regression, but in vector form, plus the regularization term from lesson 4:\n",
    "\n",
    "$$\n",
    "\\rm{loss} = - \\sum_{i=1}^{N} y_{\\text{true}}^{(i)}\\log\\left(\\hat{y}^{(i)}\\right) + \\left(1-y_{\\text{true}}^{(i)}\\right)\\log\\left(1-\\hat{y}^{(i)}\\right) + \\lambda\\sum_{i=1}^{n}{w_i}^2\n",
    "$$\n",
    "\n",
    "Or, in a vector form:\n",
    "\n",
    "$$\n",
    "\\rm{loss} = - \\left[\n",
    "\\mathbf{y}_{\\text{true}}\\cdot\\log\\left(\\mathbf{\\hat{y}}\\right)+\n",
    "\\left(1-\\mathbf{y}_{\\text{true}}\\right)\\cdot\\log\\left(1-\\mathbf{\\hat{y}}\\right)\\\n",
    "\\right]  + \\lambda\\sum_{i=1}^{n}{w_i}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(x, true_labels, params, _lambda=1.0):\n",
    "    \"\"\"Calculate the predictions and the loss w.r.t. the true values.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    x : numpy.ndarray\n",
    "        The input of the model. The shape should be (n_images, n_total_pixels).\n",
    "    true_labels : numpy.ndarray\n",
    "        The true labels of the input images. Should be 1D and have length of\n",
    "        n_images.\n",
    "    params : a tuple/list of two elements\n",
    "        The first element is a 2D array with shape (n_total_pixels, 1). The\n",
    "        second elenment is a scalar.\n",
    "    _lambda : float\n",
    "        The weight of the regularization term. Default: 1.0\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    loss : a scalar\n",
    "        The summed loss.\n",
    "    \"\"\"\n",
    "    pred = logistic_model(x, params)\n",
    "    \n",
    "    loss = - (\n",
    "        numpy.dot(true_labels, numpy.log(pred+1e-15)) +\n",
    "        numpy.dot(1.-true_labels, numpy.log(1.-pred+1e-15))\n",
    "    ) + _lambda * numpy.sum(params[0]**2)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes:\n",
    "\n",
    "1. We added a tiny term `1e-15` to the `log` calculation to avoid the infinity when `pred` or/and `1-pred` are zero.\n",
    "2. The function `model_loss` combines the calculations of model predictions and the loss. By doing so, we can easily calculate the gradients using the `grad` from `autograd`, just like we did in lesson 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, validation, and test datasets\n",
    "\n",
    "The goal of a machine learning model is to predict something that it never sees during training. For this reason, we should evaluate the performance (e.g., accuracy) of a machine learning model against data that are not part of training. The data, however, should be similar to the training data.\n",
    "\n",
    "Model optimization (i.e., model fitting) is referred to as _training_ the model in analogy to teaching humans. In school, students practice with take-home exercises. Throughout the semester, you have quizzes to monitor your learning progress. And at the end of the semester, teachers evaluate your performance using final exams. The problems in quizzes and final exams are different from take-home exercises but similar enough. A well-trained student should be able to solve them using the knowledge learned from take-home exercises.\n",
    "\n",
    "Training a machine learning model is similar. We split our data into three datasets: **training**, **validation**, and **test** datasets. We use the training dataset to train the model and monitor the learning progress using the validation dataset during the training. At the end of the training, we use the test dataset to evaluate the model's final performance.\n",
    "\n",
    "Updating the model parameters using gradient descent only requires the training dataset. Every several optimization iterations, we can evaluate the current performance using the validation dataset and adjust the training strategy in real-time accordingly. This adjustment is called **hyperparameter tuning**. We will talk about hyperparameter tuning in later lessons. On the other hand, if the training progress is satisfying and reaches our performance goal, we can stop the optimization iterations earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have no rigorous theory for how big the training, validation, and test datasets should be. Nevertheless, for a dataset as small as what we have in this lesson (i.e., 1300 images), a typical split is 60% for training, 20% for validation, and the remaining 20% for testing.\n",
    "\n",
    "The code below splits the data with these proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers of images for validation (~ 20%)\n",
    "n_ok_val = int(n_ok_total * 0.2)\n",
    "n_def_val = int(n_def_total * 0.2)\n",
    "print(\"Number of images without defects in validation dataset:\", n_ok_val)\n",
    "print(\"Number of images with defects in validation dataset:\", n_def_val)\n",
    "\n",
    "# numbers of images for test (~ 20%)\n",
    "n_ok_test = int(n_ok_total * 0.2)\n",
    "n_def_test = int(n_def_total * 0.2)\n",
    "print(\"Number of images without defects in test dataset:\", n_ok_test)\n",
    "print(\"Number of images with defects in test dataset:\", n_def_test)\n",
    "\n",
    "# remaining images for training (~ 60%)\n",
    "n_ok_train = n_ok_total - n_ok_val - n_ok_test\n",
    "n_def_train = n_def_total - n_def_val - n_def_test\n",
    "print(\"Number of images without defects in training dataset:\", n_ok_train)\n",
    "print(\"Number of images with defects in training dataset:\", n_def_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After determining the numbers of images in the three datasets, we use [`numpy.split()`](https://numpy.org/doc/stable/reference/generated/numpy.split.html) to do the splitting. Be sure to reaad the documentation for this handy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_images = numpy.split(ok_images, [n_ok_val, n_ok_val+n_ok_test], 0)\n",
    "def_images = numpy.split(def_images, [n_def_val, n_def_val+n_def_test], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to combine the images with and without defects. We use `numpy.concatenate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_val = numpy.concatenate([ok_images[0], def_images[0]], 0)\n",
    "images_test = numpy.concatenate([ok_images[1], def_images[1]], 0)\n",
    "images_train = numpy.concatenate([ok_images[2], def_images[2]], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `pyplot.imshow` to visualize the images in these three datasets, just like we did previously. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data normalization: z-score normalization\n",
    "\n",
    "In lesson 3, you learned about data normalization and a technique called min-max scaling. Here, we introduce an alternative method called **z-score normalization**:\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu_{\\text{train}}}{\\sigma_{\\text{train}}}\n",
    "$$\n",
    "\n",
    "Here, $\\mu_{\\text{train}}$ and $\\sigma_{\\text{train}}$ denote the mean value and the standard deviation of the training dataset. Remember that no matter whether $x$ represents training, validation, or test datasets, we always have to use the mean value and the standard deviation from the _training_ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mu and sigma\n",
    "mu = numpy.mean(images_train, axis=0)\n",
    "sigma = numpy.std(images_train, axis=0)\n",
    "\n",
    "# normalize the training, validation, and test datasets\n",
    "images_train = (images_train - mu) / sigma\n",
    "images_val = (images_val - mu) / sigma\n",
    "images_test = (images_test - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes:\n",
    "\n",
    "1. $\\mu_{\\text{train}}$ and $\\sigma_{\\text{train}}$ are the mean and the standard deviations of pixels across different images. So the shape of `mu` and `sigma` should be the same as the image resolution, which is `(128, 128)` for this particular dataset.\n",
    "2. After the z-score normalization, the resulting training dataset has mean value of $0$ and standard deviations of $1$ for all pixels.\n",
    "3. We normalize the validation and test datasets with the training dataset's mean and standard deviations. However, normalized validation and test datasets should have mean and standard deviations close to 0 and 1 because validation and test data should be similar to training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating labels/classes\n",
    "\n",
    "We now have images as input data to train a model. We will need to provide the correct labels for these images, corresponding to defective and normal parts. It's analogous to your teacher giving you the solutions to take-home exercises, for you to practice.\n",
    "\n",
    "To label the images, we use $1$ to represent defective parts, and $0$ for normal parts. The code below creates `labels_train`, `labels_val`, and `labels_test`, which hold the labels for the images in training, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels for training data\n",
    "labels_train = numpy.zeros(n_ok_train+n_def_train)\n",
    "labels_train[n_ok_train:] = 1.\n",
    "\n",
    "# labels for validation data\n",
    "labels_val = numpy.zeros(n_ok_val+n_def_val)\n",
    "labels_val[n_ok_val:] = 1.\n",
    "\n",
    "# labels for test data\n",
    "labels_test = numpy.zeros(n_ok_test+n_def_test)\n",
    "labels_test[n_ok_test:] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, recall that a logistic model only predicts a casting part's probability of having defects. We need to set a decision threshold and say that if a probability is higher than this threshold, the corresponding casting part is defective. Like in lesson 2, we use $0.5$ for the threshold here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(x, params):\n",
    "    \"\"\"Use a logistic model to label data with 0 or/and 1.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    x : numpy.ndarray\n",
    "        The input of the model. The shape should be (n_images, n_total_pixels).\n",
    "    params : a tuple/list of two elements\n",
    "        The first element is a 2D array with shape (n_total_pixels, 1). The\n",
    "        second elenment is a scalar.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    labels : numpy.ndarray\n",
    "        The shape of the label is the same with `probability`.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    This function only works with multiple images, i.e., x has a shape of\n",
    "    (n_images, n_total_pixels).\n",
    "    \"\"\"\n",
    "    probabilities = logistic_model(x, params)\n",
    "    labels = (probabilities >= 0.5).astype(float)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model performance: F-score\n",
    "\n",
    "Before we train our model, we need to define some metrics to evaluate the performance against the validation data _during_ training. We consider four possible outcomes of the prediction results:\n",
    "\n",
    "1. **True-positive (TP)**: the model predicts that a part has defects, and it does.\n",
    "2. **False-positive (FP)**: the model predicts that a part has defects, but it does not.\n",
    "3. **True-negative (TN)**: the model predicts that a part does not have defects, and it does not.\n",
    "4. **False-negative (FN)**: the model predicts that a part does not have defects, but it does.\n",
    "\n",
    "A table called a [**confusion matrix**](https://en.wikipedia.org/wiki/Confusion_matrix) or **error matrix** summarizes the four outcomes:\n",
    "\n",
    "|                           | w/ defects (predicted) | w/o defects (predicted) |\n",
    "|---------------------------|------------------------|-------------------------|\n",
    "| w/ defects (true answer)  | $N_{TP}$               | $N_{FN}$                |\n",
    "| w/o defects (true answer) | $N_{FP}$               | $N_{TN}$                |\n",
    "\n",
    "$N_{TP}$, $N_{FP}$, $N_{FN}$, and $N_{TN}$ denote the numbers of images with each of the four outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an error matrix, we can define several metrics to evaluate the performance; the most basic ones are **precision** and **recall**.\n",
    "Precision measures how many parts actually have defects among those predicted to be defective. Recall means how many defective parts are actually caught by the model.\n",
    "\n",
    "$$\n",
    "\\mathrm{precision}\\equiv\\frac{\\text{number of defective parts identified by the model}}{\\text{predicted total number of defective parts}} = \\frac{N_{TP}}{N_{TP}+N_{FP}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{recall}\\equiv\\frac{\\text{number of defective parts identified by the model}}{\\text{total number of defective parts}} = \\frac{N_{TP}}{N_{TP}+N_{FN}}\n",
    "$$\n",
    "\n",
    "The two metrics together measure the model performance.\n",
    "For example, a model with low precision but high recall successfully catches most defective parts, but also misjudges many perfect parts. This causes many perfect parts to be discarded and increases the cost of manufacturing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since using a single number to evaluate the performance is often desirable, we can define the **F-score** as a metric combining both precision and recall into one single value:\n",
    "\n",
    "$$\n",
    "\\text{F-score}\\equiv\\frac{\\left(1+\\beta^2\\right)\\mathrm{precision}\\times\\mathrm{recall}}{\\beta^2 \\mathrm{precision} + \\mathrm{recall}}\n",
    "$$\n",
    "\n",
    "$\\beta$ is a user-defined coefficient representing the weight of recall. A higher $\\beta$ means recall is more important than precision, and vice versa. When $\\beta=1$, we don't have any preference over precision or recall. Let's pick that for this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(predictions, answers, beta=1.0):\n",
    "    \"\"\"Calculate precision, recall, and F-score.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    predictions : numpy.ndarray of integers\n",
    "        The predicted labels.\n",
    "    answers : numpy.ndarray of integers\n",
    "        The true labels.\n",
    "    beta : float\n",
    "        A coefficient representing the weight of recall.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    precision, recall, score : float\n",
    "        Precision, recall, and F-score, respectively.\n",
    "    \"\"\"\n",
    "    true_idx = (answers == 1)  # the location where the answers are 1\n",
    "    false_idx = (answers == 0)  # the location where the answers are 0\n",
    "    \n",
    "    # true positive: answers are 1 and predictions are also 1\n",
    "    n_tp = numpy.count_nonzero(predictions[true_idx] == 1)\n",
    "    \n",
    "    # false positive: answers are 0 but predictions are 1\n",
    "    n_fp = numpy.count_nonzero(predictions[false_idx] == 1)\n",
    "    \n",
    "    # true negative: answers are 0 and predictions are also 0\n",
    "    n_tn = numpy.count_nonzero(predictions[false_idx] == 0)\n",
    "    \n",
    "    # false negative: answers are 1 but predictions are 0\n",
    "    n_fn = numpy.count_nonzero(predictions[true_idx] == 0)\n",
    "    \n",
    "    # precision, recall, and f-score\n",
    "    precision = n_tp / (n_tp + n_fp)\n",
    "    recall = n_tp / (n_tp + n_fn)\n",
    "    score = (\n",
    "        (1.0 + beta**2) * precision * recall / \n",
    "        (beta**2 * precision + recall)\n",
    "    )\n",
    "\n",
    "    return precision, recall, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A higher F-score is better. A perfect model has F-score of one (or $100\\%$) regardless of $\\beta$, which means both precision and recall are $100\\%$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Let's initialize the parameters to zero, and use `grad` to compute derivatives with respect to the parameters, as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to get the gradients of a logistic model\n",
    "gradients = grad(model_loss, argnum=2)\n",
    "\n",
    "# initialize parameters\n",
    "w = numpy.zeros((images_train.shape[1], 1), dtype=float)\n",
    "b = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we calculate the initial F-score against the test dataset to see how much the improvement is after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial accuracy\n",
    "pred_labels_test = classify(images_test, (w, b))\n",
    "perf = performance(pred_labels_test, labels_test)\n",
    "\n",
    "print(\"Initial precision]: {:.1f}%\".format(perf[0]*100))\n",
    "print(\"Initial recall: {:.1f}%\".format(perf[1]*100))\n",
    "print(\"Initial F-score: {:.1f}%\".format(perf[2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be surprised at the not-so-bad initial performance. In fact, this initial performance is skewed by the improper design of the datasets.\n",
    "\n",
    "Due to the all-zero initial parameters, the model initially predicts that all parts have defects. In other words, the variable `pred_labels_test` is an array of ones. Now, remember that we have 103 normal parts and 156 defective parts in our test dataset. With an initial prediction of all parts being defective, we have the following error matrix:\n",
    "\n",
    "|                           | w/ defects (predicted) | w/o defects (predicted) |\n",
    "|---------------------------|------------------------|-------------------------|\n",
    "| w/ defects (true answer)  | $N_{TP}=156$           | $N_{FN}=0$              |\n",
    "| w/o defects (true answer) | $N_{FP}=103$           | $N_{TN}=0$              |\n",
    "\n",
    "Then the initial precision is about $60.2\\%$, and the initial recall is exactly $100\\%$. The initial F-score is $75.2\\%$\n",
    "\n",
    "The high initial performance comes from having more defective parts than normal parts in the test dataset. Designing a proper ratio between data labeled with 1 and 2 is therefore critical. It's like designing and answering true-false questions of an exam. If the correct answers to a set of true-false questions are mostly true, and a lazy student guesses true for all questions and finishes the quiz in one minute, they can get a very high score! Yet that score does not truly represent the student's knowledge level.\n",
    "\n",
    "In machine learning, test and validation data should mimic real-world data. For example, if 98% of production from a casting factory meets the quality criterion, using a test dataset with 156 defective and 103 normal parts may be improper.\n",
    "\n",
    "In this lesson, we will leave the datasets as-is. Designing a good dataset is application-dependent: it requires deep knowledge and experience in the corresponding field of application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/optimization\n",
    "\n",
    "In the optimization loop (using gradient descent), we'll monitor the progress of training using the validation dataset. If the validation loss is not changing much, we'll stop the training.\n",
    "\n",
    "Here, we only use validation loss to control the optimization. In real applications, it's common to use a combination of validation loss, accuracy, and other metrics to control the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# learning rate\n",
    "lr = 1e-5\n",
    "\n",
    "# a variable for the change in validation loss\n",
    "change = numpy.inf\n",
    "\n",
    "# a counter for optimization iterations\n",
    "i = 0\n",
    "\n",
    "# a variable to store the validation loss from the previous iteration\n",
    "old_val_loss = 1e-15\n",
    "\n",
    "# keep running if:\n",
    "#   1. we still see significant changes in validation loss\n",
    "#   2. iteration counter < 10000\n",
    "while change >= 1e-5 and i < 10000:\n",
    "    \n",
    "    # calculate gradients and use gradient descents\n",
    "    grads = gradients(images_train, labels_train, (w, b))\n",
    "    w -= (grads[0] * lr)\n",
    "    b -= (grads[1] * lr)\n",
    "    \n",
    "    # validation loss\n",
    "    val_loss = model_loss(images_val, labels_val, (w, b))\n",
    "    \n",
    "    # calculate f-scores against the validation dataset\n",
    "    pred_labels_val = classify(images_val, (w, b))\n",
    "    score = performance(pred_labels_val, labels_val)\n",
    "\n",
    "    # calculate the chage in validation loss\n",
    "    change = numpy.abs((val_loss-old_val_loss)/old_val_loss)\n",
    "\n",
    "    # update the counter and old_val_loss\n",
    "    i += 1\n",
    "    old_val_loss = val_loss\n",
    "    \n",
    "    # print the progress every 10 steps\n",
    "    if i % 10 == 0:\n",
    "        print(\"{}...\".format(i), end=\"\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Upon optimization stopped:\")\n",
    "print(\"    Iterations:\", i)\n",
    "print(\"    Validation loss:\", val_loss)\n",
    "print(\"    Validation precision:\", score[0])\n",
    "print(\"    Validation recall:\", score[1])\n",
    "print(\"    Validation F-score:\", score[2])\n",
    "print(\"    Change in validation loss:\", change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't use the validation F-score to stop the optimization because improving the predicted probability does not necessarily improve the predicted labels. For example, suppose the probabilities predicted by the logistic model during the last three iterations are $0.1$, $0.2$, and $0.3$. In that case, the predicted labels are still $0$, $0$, and $0$ for the three iterations. Hence monitoring F-score (which relies on predicted labels) will cause the optimization to stop too early while the model is still improving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's examine the model's performance using the test dataset and see if it's better than the initial performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final accuracy\n",
    "pred_labels_test = classify(images_test, (w, b))\n",
    "perf = performance(pred_labels_test, labels_test)\n",
    "\n",
    "print(\"Final precision: {:.1f}%\".format(perf[0]*100))\n",
    "print(\"Final recall: {:.1f}%\".format(perf[1]*100))\n",
    "print(\"Final F-score: {:.1f}%\".format(perf[2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bravo! The precision improved from $60.2\\%$ to $88.0\\%$, which means when our model says a part has defects, there is an $88.0\\%$ chance it is indeed defective. The recall dropped from $100%$ to $84.6\\%$, which means our model misses about $15\\%$ of the defective parts. The F-score, representing overall accuracy, improved from $75.2\\%$ to $86.3\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No model is perfect, so it's not realistic to expect $100\\%$ accuracy. There's no standard for how accurate a model should be to consider it a good model. Nevertheless, an F-score of $86.3\\%$ does not seem to be exciting. Especially in this example, about $15\\%$ of defective products slip through and may be handed over to customers.\n",
    "\n",
    "In the next lesson, we will improve the performance by replacing the multiple logistic regression model with something more interesting: a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we've learned\n",
    "\n",
    "1. apply multiple logistic regression to identify defective metal-casting parts,\n",
    "2. split data into training, validation, and test datasets,\n",
    "3. normalize data using z-score, and\n",
    "4. evaluate the performance of a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "1. Kantesaria, N., Vaghasia, P., Hirpara, J., & Bhoraniya, R., (2020). Casting product image data for quality inspection. Kaggle. https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell to load the notebook's style sheet, then ignore it\n",
    "from IPython.core.display import HTML\n",
    "css_file = '../style/custom.css'\n",
    "HTML(open(css_file, \"r\").read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
