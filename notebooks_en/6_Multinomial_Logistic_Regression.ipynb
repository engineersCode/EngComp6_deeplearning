{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2109382b",
   "metadata": {},
   "source": [
    "###### Content under Creative Commons Attribution license CC-BY 4.0, code under BSD 3-Clause License Â© 2021 Lorena A. Barba, Tingyu Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9081529",
   "metadata": {},
   "source": [
    "# Multinomial logistic regression\n",
    "\n",
    "In the previous lesson, we extended the logistic regression model by using multiple features (pixels of an image) to identify defective parts.\n",
    "Since our data only have two class labels: \"okay\" and \"defective\", this problem is considered a binary classification problem.\n",
    "What if we are asked to classify a dataset into multiple class labels, for instance, grade the quality of metal parts into A,B,C?\n",
    "In this notebook, we will introduce multinomial logistic regression to identify whether the sentiment of a tweet is negative, neutral or positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010eb1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import numpy\n",
    "from autograd import grad\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be96b18",
   "metadata": {},
   "source": [
    "## Preprocess the tweets\n",
    "\n",
    "The original dataset in this lesson comes from US air travelers' tweets in Februrary 2015, see Reference [1].\n",
    "Each tweet expresses a passenger's feelings about the flight experience, and is labeled as negative, neutral or positive. \n",
    "\n",
    "Let's read in the data and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d58da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('../data/tweets.csv')\n",
    "pd.set_option('display.max_colwidth', None)  # display tweets using max width of cell\n",
    "print(f\"{tweets.shape = }\")\n",
    "num_samples = tweets.shape[0]\n",
    "tweets.sample(10, random_state=0)  # fix random_state for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f1f1bd",
   "metadata": {},
   "source": [
    "There are 14k tweets in the dataset.\n",
    "Each entry consist of the text of the tweet and its sentiment.\n",
    "Our goal is to classify the sentiment of these tweets into the three labels.\n",
    "Before we move on, let us check the and the percentage of each sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc546a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.airline_sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dddb71b",
   "metadata": {},
   "source": [
    "As you might have guessed, a negative experience is more likely to lead to a tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445c69e",
   "metadata": {},
   "source": [
    "### Cleaning the text data\n",
    "\n",
    "Up to this point, we are always given the feature arrays directly.\n",
    "Even when the dataset consists of images, as in the metal-casting parts example, the grayscale images are represented as 2D arrays.\n",
    "However, this is not the case for text data, like the tweets in this lesson.\n",
    "\n",
    "In this lesson, we will briefly walk through how to clean raw text data and transform them into feature arrays.\n",
    "Though this is not the main focus of this lesson, we hope it can provide you at least a high-level understanding of how text data are dealt with in real-world applications.\n",
    "\n",
    "Let's import a script that we prepared to faciliate the preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c581a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "from lesson6_helpers import clean_tweet, LemmaTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88fbc12",
   "metadata": {},
   "source": [
    "The first step is always cleaning the data.\n",
    "Specially for our dataset, we clean the strings by removing non-alphabetic characters (numbers, symbols, punctuations), lowercasing all letters, and removing stop words.\n",
    "The first two operations are relatively easy to understand.\n",
    "And stop words are some commonly used words, such as \"a\", \"the\", \"or\" and \"will\", that often carry very little information in a sentence compared with other words.\n",
    "Removing them can reduce the size of data.\n",
    "\n",
    "Let's clean the tweets and save the results in the `clean_tweet` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e153eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_tweet'] = tweets['text'].apply(lambda x: clean_tweet(x))\n",
    "tweets.sample(5, random_state=6)   # fix random_state for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42d5b90",
   "metadata": {},
   "source": [
    "### Training, validation, test split\n",
    "\n",
    "Next, we split the data into three sets: training, validation and test datasets, as discussed in lesson 5.\n",
    "As a recap, we fit the model with the training set, monitor the learning progress and tune the hyperparameters using the validation set, and evaluate the performance of the final tuned model using the test set.\n",
    "\n",
    "Let's split our dataset in a 60/20/20 fashion.\n",
    "Recall that we splitted `ok_images` and `def_images` in lesson 5 respectively and then combined them to preserve the defective ratio in each of the three sets.\n",
    "The same idea also applies to data with multi-class labels.\n",
    "Here we want to keep the same negative-neutral-positive ratio across the three sets as the complete set.\n",
    "\n",
    "Let's use the scikit-learn function [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) this time for convenience.\n",
    "As its name suggests, this function can only split a dataset into two parts.\n",
    "Therefore, we first split the data into `train` (80%) and `test` (20%), and then split the `train` (80%) again into the \"real\" `train` (60%) and `validation` (20%).\n",
    "We also turn on the `stratify` option to preserve the negative-neutral-positive ratio in each set.\n",
    "Let's execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a0a13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 0   # fix random_state for reproducibility\n",
    "train, test = train_test_split(tweets, test_size=0.2,\n",
    "                               random_state=random_state,\n",
    "                               stratify=tweets['airline_sentiment'])\n",
    "train, val = train_test_split(train, test_size=0.25,\n",
    "                              random_state=random_state,\n",
    "                              stratify=train['airline_sentiment'])\n",
    "\n",
    "print(\"--- training set ---\")\n",
    "print(train['airline_sentiment'].value_counts(normalize=True))\n",
    "print(f\"{train.shape = }\")\n",
    "print(\"\\n-- validation set --\")\n",
    "print(val['airline_sentiment'].value_counts(normalize=True))\n",
    "print(f\"{val.shape = }\")\n",
    "print(\"\\n----- test set -----\")\n",
    "print(test['airline_sentiment'].value_counts(normalize=True))\n",
    "print(f\"{test.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da7f0a",
   "metadata": {},
   "source": [
    "### Transform text into feature vectors\n",
    "\n",
    "The next step is to convert the cleaned tweets into vectors of features $\\mathbf{x}$. To help you understand the method we will use, let's consider the toy example below, borrowed from this [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). Suppose a new dataset only has four samples (tweets):\n",
    "\n",
    "```Python\n",
    "corpus = [\n",
    "...     'This is the first document.',\n",
    "...     'This document is the second document.',\n",
    "...     'And this is the third one.',\n",
    "...     'Is this the first document?',\n",
    "... ]\n",
    "```\n",
    "\n",
    "There are 9 **unique** words in the corpus. Let's index them as below.\n",
    "\n",
    "| `and` | `document` | `first` | `is` | `one` | `second` | `the` | `third` | `this`|\n",
    "|-------|------------|---------|------|-------|----------|-------|---------|-------|\n",
    "|   0   |      1     |    2    |   3  |   4   |     5    |   6   |    7    |    8  |\n",
    "\n",
    "If we treat each unique word as a feature, we can then use a vector of word counts to represent a string.\n",
    "For example, the second sample: `This document is the second document` has $2$ `document`s, $1$ `is`, $1$ `second`, $1$ `the` and $1$ `this`. Based on the table of unique words' indices above, its feature vector can be written as:\n",
    "```Python\n",
    "[0 2 0 1 0 1 1 0 1]\n",
    "```\n",
    ", and similarly, we can convert this dataset into a feature matrix $X$:\n",
    "```Python\n",
    "[[0 1 1 1 0 0 1 0 1]\n",
    " [0 2 0 1 0 1 1 0 1]\n",
    " [1 0 0 1 1 0 1 1 1]\n",
    " [0 1 1 1 0 0 1 0 1]]\n",
    "```\n",
    ", which has a shape of `(num_samples, num_unique_words)`.\n",
    "\n",
    "[`CountVectorizer()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) in scikit-learn offers such functionality in a user-friendly way.\n",
    "Let's run the cell below to generate feature arrays $X$ for all three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679f710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer())\n",
    "\n",
    "X_train = vectorizer.fit_transform(train.clean_tweet).astype('float').toarray()\n",
    "X_val = vectorizer.transform(val.clean_tweet).astype('float').toarray()\n",
    "X_test = vectorizer.transform(test.clean_tweet).astype('float').toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f58e99",
   "metadata": {},
   "source": [
    "The variable `vectorizer` indexes the unique words from the training set and we generate these feature arrays accordingly using `fit_transform()` or `transform()` (the difference explained in lesson 4). Check `vectorizer.vocabulary_` if you are curious of the underlying mapping from unique words to indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251aaa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{X_train.shape = }\")\n",
    "print(f\"{X_val.shape   = }\")\n",
    "print(f\"{X_test.shape  = }\")\n",
    "\n",
    "num_features = X_train.shape[1]   # equals to the number of unique words in training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3779729e",
   "metadata": {},
   "source": [
    "### One-hot encoding for output variable\n",
    "\n",
    "After preparing the feature arrays, let's work on the output variable `airline_sentiment`, whose still has a string-like type at the moment.\n",
    "We need to convert these categorical data into something we can compute with.\n",
    "In the lesson 5, we set $y_{\\rm{true}} = 1$ for defective parts and $y_{\\rm{true}} = 0$ for normal parts.\n",
    "When we have multiple classes, e.g., $3$ classes in this context, we often use a vector $\\mathbf{y}_\\rm{true}$ instead of a scalar to represent the categories.\n",
    "In our case, we set:\n",
    "\n",
    "- $\\mathbf{y}_\\rm{true} = (1, 0, 0)^{\\mathsf{T}}$ corresponds to `negative` tweets.\n",
    "- $\\mathbf{y}_\\rm{true} = (0, 1, 0)^{\\mathsf{T}}$ corresponds to `neutral` tweets.\n",
    "- $\\mathbf{y}_\\rm{true} = (0, 0, 1)^{\\mathsf{T}}$ corresponds to `positve` tweets.\n",
    "\n",
    "for a single sample. This method is called **one-hot encoding**, where we assign a column to each class, and all elements are $0$ except one, which is set to $1$.\n",
    "For convenience, let's use `OneHotEncoder()` from scikit-learn to obtain $\\mathbf{y}_\\rm{true}$ for all samples in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()   # check encoder.categories_\n",
    "Y_train_true = encoder.fit_transform(train[['airline_sentiment']]).toarray()\n",
    "Y_val_true = encoder.transform(val[['airline_sentiment']]).toarray()\n",
    "Y_test_true = encoder.transform(test[['airline_sentiment']]).toarray()\n",
    "\n",
    "num_classes = Y_train_true.shape[1]\n",
    "\n",
    "print(f\"{Y_train_true.shape = }\")\n",
    "print(f\"{Y_val_true.shape = }\")\n",
    "print(f\"{Y_test_true.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3d3444",
   "metadata": {},
   "source": [
    "Notice that we use the uppercase `Y` in the variable name, since it is now a matrix $Y_\\rm{true}$.\n",
    "Each row is the one-hot vector for a single sample.\n",
    "\n",
    "Let's check these values for a few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(Y_train_true[i], train['airline_sentiment'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e3f78",
   "metadata": {},
   "source": [
    "As you can see, preprocessing is nontrivial and in fact equally important as training in real applications.\n",
    "Let's move to the model fitting part of this lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3211e4c",
   "metadata": {},
   "source": [
    "## Multinomial Regression model\n",
    "\n",
    "Recall that the multiple logistic regression model is a combination of a linear prediction and the logistic function:\n",
    "\n",
    "$$\n",
    "z = \\mathbf{x} \\cdot \\mathbf{w} + b =  \\mathbf{x}^\\mathsf{T} \\mathbf{w} + b \\\\\n",
    "\\hat{y} = \\operatorname{logistic}(z) = \\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{x}$ is the feature vector a single sample.\n",
    "The logistic function takes a scalar $z$ and outputs a value between $0$ and $1$. In the context of binary classification problems, $\\hat{y}$ is interpreted as the probablity of a sample $\\mathbf{x}$ being class $1$; and naturally, the probability of the sample being class $0$ is $1-\\hat{y}$ since the probablities should sum up to $1$.\n",
    "\n",
    "However, when the dependent variable has multiple class labels, e.g. $m$ labels, intuitively we need $m$ probablities to describe our prediction.\n",
    "Therefore, we need $m$ separate linear predictions (one for each label) and our linear prediction $z$ will become an $m$-element vector $\\mathbf{z}$.\n",
    "\n",
    "Suppose each sample has $d$ features, the linear predictions $\\mathbf{z} = (z_1, z_2, \\cdots, z_d)^\\mathsf{T}$ of a single sample $\\mathbf{x}$ can be written as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z_1 &= b_1 + w_{1,1} x_1 + w_{2,1} x_2 + \\cdots + w_{d,1} x_{d} \\\\\n",
    "z_2 &= b_2 + w_{1,2} x_1 + w_{2,2} x_2 + \\cdots + w_{d,2} x_{d} \\\\\n",
    "\\vdots & \\\\\n",
    "z_m &= b_m + w_{1,m} x_1 + w_{2,m} x_2 + \\cdots + w_{d,m} x_{d} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We also have $m$ different intercepts here, as if we are doing $m$ separate linear regressions.\n",
    "Each weight now has two subscripts: the first one corresponds to the feature, the second corresponds to the output label.\n",
    "As you can see, the weights form a $d\\times m$ matrix when you have multiclass labels.\n",
    "We can write this in vector form as:\n",
    "\n",
    "$$\n",
    "\\underset{m\\times 1}{\\mathbf{z}} = \\underset{m \\times d}{W^{\\mathsf{T}}} \\  \\underset{d\\times 1}{\\mathbf{x}} + \\underset{m\\times 1}{\\mathbf{b}}\n",
    "$$\n",
    "\n",
    "where the intercept term is now a vector $\\mathbf{b} = (b_1, b_2, \\cdots, b_m)^\\mathsf{T}$.\n",
    "\n",
    "In the logistic regression, we then use logistic function to map $z$ into a probability $\\hat{y}$.\n",
    "Similarly, for multiclass problems, we need to find a function that maps vector $\\mathbf{z}$ into a discrete probability distribution $\\hat{\\mathbf{y}}$ over $m$ outcomes (labels).\n",
    "\n",
    "\n",
    "The softmax function just serves this purpose: \n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{\\mathbf{y}}} = \\operatorname{softmax(\\mathbf{z})}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\hat{y}_i = \\operatorname{softmax}(\\mathbf{z})_{i}=\\frac{e^{z_{i}}}{\\sum_{j=1}^{m} e^{z_{j}}} \\quad \\text { for } i=1, \\ldots, m .\n",
    "$$\n",
    "\n",
    "It basically computes the exponential of each linear prediction $z_i$ and normalizes it with the sum.\n",
    "The elements of $\\hat{\\mathbf{y}}$ are from $0$ to $1$ and they also sum up to $1$.\n",
    "Hence $\\hat{\\mathbf{y}}$ can be interpreted as a probability distribution over $m$ class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcf6eea",
   "metadata": {},
   "source": [
    "### Matrix form\n",
    "\n",
    "Let's derive the matrix form that can handle $N$ samples.\n",
    "The formulation above works for a single sample $\\mathbf{x}$,\n",
    "i.e., $\\mathbf{z}^{(i)} = W^{\\mathsf{T}} \\mathbf{x}^{(i)} + \\mathbf{b}$ for the $i$-th sample (remember that we use superscript with parentheses to denote sample index).\n",
    "By stacking these $\\mathbf{z}^{(i)}$ together on LHS and combining the mat-vecs to mat-mat on RHS, we get:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cccc}\n",
    "    \\mid & \\mid & & \\mid \\\\\n",
    "    \\mathbf{z}^{(1)} & \\mathbf{z}^{(2)} & \\cdots & \\mathbf{z}^{(N)} \\\\\n",
    "    \\mid & \\mid & & \\mid\n",
    "\\end{array}\\right]\n",
    "= W^{\\mathsf{T}}\n",
    "\\left[\\begin{array}{cccc}\n",
    "    \\mid & \\mid & & \\mid \\\\\n",
    "    \\mathbf{x}^{(1)} & \\mathbf{x}^{(2)} & \\cdots & \\mathbf{x}^{(N)} \\\\\n",
    "    \\mid & \\mid & & \\mid\n",
    "\\end{array}\\right]\n",
    "+\n",
    "\\left[\\begin{array}{cccc}\n",
    "    \\mid & \\mid & & \\mid \\\\\n",
    "    \\mathbf{b} & \\mathbf{b} & \\cdots & \\mathbf{b} \\\\\n",
    "    \\mid & \\mid & & \\mid\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "However, in our feature array $X$, each sample occupies a row:\n",
    "\n",
    "$$\n",
    "X = \n",
    "\\left[\\begin{array}{ccc}\n",
    "    - & {\\mathbf{x}^{(1)}}^{\\mathsf{T}} & - \\\\\n",
    "    - & {\\mathbf{x}^{(2)}}^{\\mathsf{T}} & - \\\\\n",
    "    & \\vdots & \\\\\n",
    "    - & {\\mathbf{x}^{(N)}}^{\\mathsf{T}} & -\n",
    "\\end{array}\\right].\n",
    "$$\n",
    "\n",
    "To keep the convention of using rows to represent samples, we transpose both sides of the matrix form above:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{ccc}\n",
    "    - & {\\mathbf{z}^{(1)}}^{\\mathsf{T}} & - \\\\\n",
    "    - & {\\mathbf{z}^{(2)}}^{\\mathsf{T}} & - \\\\\n",
    "    & \\vdots & \\\\\n",
    "    - & {\\mathbf{z}^{(N)}}^{\\mathsf{T}} & -\n",
    "\\end{array}\\right]\n",
    "= \n",
    "\\left[\\begin{array}{ccc}\n",
    "    - & {\\mathbf{x}^{(1)}}^{\\mathsf{T}} & - \\\\\n",
    "    - & {\\mathbf{x}^{(2)}}^{\\mathsf{T}} & - \\\\\n",
    "    & \\vdots & \\\\\n",
    "    - & {\\mathbf{x}^{(N)}}^{\\mathsf{T}} & -\n",
    "\\end{array}\\right]\n",
    "W\n",
    "+\n",
    "\\left[\\begin{array}{ccc}\n",
    "    - & {\\mathbf{b}}^{\\mathsf{T}} & - \\\\\n",
    "    - & {\\mathbf{b}}^{\\mathsf{T}} & - \\\\\n",
    "    & \\vdots & \\\\\n",
    "    - & {\\mathbf{b}}^{\\mathsf{T}} & -\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "If we define the LHS as matrix $Z$ and the intercept matrix as $B$, the matrix form can be simplified as:\n",
    "\n",
    "$$\n",
    "\\underset{N\\times m}{Z} = \\underset{N\\times d}{X} \\  \\underset{d\\times m}{W} + \\underset{N\\times m}{B}\n",
    "$$\n",
    "\n",
    "Finally, we apply softmax function to each row of $Z$ to get the prediction matrix $\\hat{Y}$:\n",
    "\n",
    "$$\n",
    "\\underset{N\\times m}{\\hat{Y}} = \n",
    "\\left[\\begin{array}{ccc}\n",
    "    - & {\\hat{\\mathbf{y}}^{(1)}}^{\\mathsf{T}} & - \\\\\n",
    "    - & {\\hat{\\mathbf{y}}^{(2)}}^{\\mathsf{T}} & - \\\\\n",
    "    & \\vdots & \\\\\n",
    "    - & {\\hat{\\mathbf{y}}^{(N)}}^{\\mathsf{T}} & -\n",
    "\\end{array}\\right].\n",
    "$$\n",
    "\n",
    "The elements of each row of $Y$ represent the probablity distribution over $m$ labels for a certain sample, and they shoud sum up to $1$.\n",
    "\n",
    "Let's code the model function together in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9dfd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_regression(X, params):\n",
    "    \"\"\" softmax regression model \"\"\"\n",
    "    W, b = params[0], params[1]      \n",
    "    Z = numpy.exp(X@W + b)  # not need to form B thanks to numpy broadcasting feature\n",
    "    Z_sum = numpy.sum(Z, axis=1, keepdims=True)\n",
    "    Y_pred = Z / Z_sum\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609c76f",
   "metadata": {},
   "source": [
    "Notice that we just add `X@W` and `b` (instead of forming the matrix $B$), despite that they have different shapes - `(num_samples, num_classes)` and `(num_classes,)` respectively.\n",
    "This is because numpy operators can broadcast the smaller array to match the shape of the bigger one (if compatible).\n",
    "We suggest to read [this documentation](https://numpy.org/devdocs/user/basics.broadcasting.html) from numpy for a better understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f96f3c",
   "metadata": {},
   "source": [
    "### Decision boundary\n",
    "\n",
    "Now that we have the probability distribution over multiple classes for a sample, we can pick the class with the highest probability as our final prediction, simply as:\n",
    "\n",
    "$$\n",
    "\\text{label} = \\underset{j}{\\operatorname{argmax}} \\hat{y}_{j}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419598bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X, params):\n",
    "    \"\"\"\n",
    "    X: 2D array\n",
    "    params:\n",
    "    \n",
    "    return\n",
    "    labels: 1D array\n",
    "    \"\"\"\n",
    "    Y_pred = softmax_regression(X, params)\n",
    "    labels = numpy.argmax(Y_pred, axis=1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437cc687",
   "metadata": {},
   "source": [
    "Let's generate the vector of true labels, which will be used to measure the performance of our model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b4d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_train = numpy.argmax(Y_train_true, axis=1)\n",
    "true_labels_val = numpy.argmax(Y_val_true, axis=1)\n",
    "true_labels_test = numpy.argmax(Y_test_true, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528bbb75",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n",
    "The log loss that we used for logistic regression without the regularization term is:\n",
    "\n",
    "$$\n",
    "\\mathrm{loss} = - \\sum_{i=1}^{N} y_{\\text{true}}^{(i)}\\log\\left(\\hat{y}^{(i)}\\right) + \\left(1-y_{\\text{true}}^{(i)}\\right)\\log\\left(1-\\hat{y}^{(i)}\\right),\n",
    "$$\n",
    "\n",
    "and we interpret $\\hat{y}^{(i)}$ as the probability of the $i$-th sample being class $1$ based on our prediction, and $1 - \\hat{y}^{(i)}$ as the probability of being class $0$.\n",
    "If we break the sum and look at the loss of an individual sample, we get:\n",
    "\n",
    "$$\n",
    "\\mathrm{one\\ sample\\ loss} = \\left\\{\n",
    "\\begin{aligned}\n",
    "-\\log \\left( 1-\\hat{y}^{(i)} \\right) & \\quad \\text { if } y_\\rm{true}^{(i)}=0 \\\\\n",
    "-\\log \\left( \\hat{y}^{(i)}   \\right) & \\quad \\text { if } y_\\rm{true}^{(i)}=1\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "As you can see, the individual loss is just the negative logarithm of the probability of predicting the true label.\n",
    "Let's apply the same philosophy to multiclass problems, and keep in mind $\\hat{\\mathbf{y}}^{(i)}$ is now a probability distribution over outcomes:\n",
    "\n",
    "$$\n",
    "\\mathrm{one\\ sample\\ loss} = \\left\\{\n",
    "\\begin{aligned}\n",
    "-\\log \\left( \\hat{y}^{(i)}_1   \\right) & \\quad \\text { if } \\mathbf{y}_\\rm{true}^{(i)}=(1,0,0)^\\mathsf{T} \\\\\n",
    "-\\log \\left( \\hat{y}^{(i)}_2 \\right) & \\quad \\text { if }  \\mathbf{y}_\\rm{true}^{(i)}=(0,1,0)^\\mathsf{T} \\\\\n",
    "-\\log \\left( \\hat{y}^{(i)}_3 \\right) & \\quad \\text { if }  \\mathbf{y}_\\rm{true}^{(i)}=(0,0,1)^\\mathsf{T}\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Because $\\mathbf{y}_\\rm{true}^{(i)}$ is a one-hot vector, we can simplify the loss as:\n",
    "\n",
    "$$\n",
    "\\mathrm{one\\ sample\\ loss} = -\\mathbf{y}_\\rm{true}^{(i)} \\cdot \\log \\left( \\hat{\\mathbf{y}}^{(i)} \\right)\n",
    "$$\n",
    "\n",
    "Therefore, the log loss generalized for multiclass problems is:\n",
    "\n",
    "$$\n",
    "\\mathrm{loss} = - \\sum_{i=1}^{N} \\mathbf{y}_\\rm{true}^{(i)} \\cdot \\log \\left( \\hat{\\mathbf{y}}^{(i)} \\right)\n",
    "$$\n",
    "\n",
    "Because the dot product is just the sum of the element-wise products, and our $\\mathbf{y}_\\rm{true}^{(i)}$ and $\\mathbf{y}^{(i)}$  are on the rows of ${Y_\\rm{true}}$ and ${\\hat{Y}}$:\n",
    "\n",
    "$$\n",
    "\\underset{N\\times m}{Y_\\rm{true}} = \n",
    "\\left[\\begin{array}{ccc}\n",
    "    - & {\\hat{\\mathbf{y}}^{(1)}_\\rm{true}}^{\\mathsf{T}} & - \\\\\n",
    "    - & {\\hat{\\mathbf{y}}^{(2)}_\\rm{true}}^{\\mathsf{T}} & - \\\\\n",
    "    & \\vdots & \\\\\n",
    "    - & {\\hat{\\mathbf{y}}^{(N)}_\\rm{true}}^{\\mathsf{T}} & -\n",
    "\\end{array}\\right]\n",
    "\\quad\n",
    "\\text{and}\n",
    "\\quad\n",
    "\\underset{N\\times m}{\\hat{Y}} = \n",
    "\\left[\\begin{array}{ccc}\n",
    "    - & {\\hat{\\mathbf{y}}^{(1)}}^{\\mathsf{T}} & - \\\\\n",
    "    - & {\\hat{\\mathbf{y}}^{(2)}}^{\\mathsf{T}} & - \\\\\n",
    "    & \\vdots & \\\\\n",
    "    - & {\\hat{\\mathbf{y}}^{(N)}}^{\\mathsf{T}} & -\n",
    "\\end{array}\\right]\\ ,\n",
    "$$\n",
    "\n",
    "we can rewrite the loss in matrix form as:\n",
    "\n",
    "$$\n",
    "\\mathrm{loss} = -\\sum_{i=1}^N \\sum_{j=1}^m \\left( Y_{\\rm{true}} \\circ \\hat{Y} \\right)_{ij} \\ ,\n",
    "$$\n",
    "\n",
    "where $\\circ$ denotes the element-wise product between two matrices of the same shape.\n",
    "\n",
    "Let's implement the loss function below and add a regularization term that includes all weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7038ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(X, Y_true, params, _lambda):\n",
    "    \n",
    "    Y_pred = softmax_regression(X, params)\n",
    "    W = params[0]\n",
    "    loss = - numpy.sum(Y_true * numpy.log(Y_pred+1e-15)) / X.shape[0] \\\n",
    "           + _lambda * numpy.sum(W*W) / (W.shape[0] * W.shape[1])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2831ab3",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Let's initialize the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the gradients function\n",
    "gradients = grad(model_loss, argnum=2)\n",
    "\n",
    "# initialize the parameters\n",
    "numpy.random.seed(10000)\n",
    "W = numpy.random.normal(scale=1e-4, size=(num_features, num_classes))  # random initial guess from normal distribution\n",
    "b = numpy.zeros(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386d7b75",
   "metadata": {},
   "source": [
    "\n",
    "We can use the same metrics to evaluate the performance as lesson 5. However, as our  data have multiple classes, we can compute precision, recall and F-score for each label.\n",
    "Again for brevity, let's use the function [`precision_recall_fscore_support()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html) from scikit-learn to check the initial accuracy.\n",
    "It takes true labels as the first argument and predicted labels as the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8841d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_test = classify(X_test, (W, b))\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(true_labels_test, pred_labels_test)\n",
    "print(f\"{precision = }\")\n",
    "print(f\"{recall    = }\")\n",
    "print(f\"{fscore    = }\")\n",
    "print(f\"{support   = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e1786",
   "metadata": {},
   "source": [
    "The return value `support` gives you the number of occurences of each class in true labels.\n",
    "Let's also compute the weighted average F-score using [`f1_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html),\n",
    "since we often prefer to use a single number to track the accuracy during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce153688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(true_labels_test, pred_labels_test, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060de718",
   "metadata": {},
   "source": [
    "### Train our model\n",
    "\n",
    "- Describe what is learning curve.\n",
    "- Explain the discrepancy between training loss and validation loss, and accuracy.\n",
    "- Save the weights, i.e., our model\n",
    "- demonstrate overfitting in learning curve (if possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91305317",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "lr = 1e-1  # learning rate\n",
    "_lambda = 1.0  # regularization parameter\n",
    "\n",
    "# a variable for the change in validation loss\n",
    "change = numpy.inf\n",
    "\n",
    "# a counter for optimization iterations\n",
    "i = 0\n",
    "\n",
    "# a variable to store the validation loss from the previous iteration\n",
    "old_loss_val = 1e-15\n",
    "\n",
    "# accuracy and loss history\n",
    "loss_train_hist = []\n",
    "loss_val_hist = []\n",
    "acc_train_hist = []\n",
    "acc_val_hist = []\n",
    "\n",
    "# keep running if:\n",
    "#   1. we still see significant changes in validation loss\n",
    "#   2. iteration counter < 10000\n",
    "\n",
    "while change >= 1e-10 and i < 1000:\n",
    "    \n",
    "    # calculate gradients and use gradient descents\n",
    "    grads = gradients(X_train, Y_train_true, (W, b), _lambda)\n",
    "    W -= (grads[0] * lr)\n",
    "    b -= (grads[1] * lr)\n",
    "    \n",
    "    # compute training & validation loss\n",
    "    loss_train = model_loss(X_train, Y_train_true, (W, b), _lambda)\n",
    "    loss_val = model_loss(X_val, Y_val_true, (W, b), _lambda)\n",
    "    loss_train_hist.append(loss_train)\n",
    "    loss_val_hist.append(loss_val)\n",
    "     \n",
    "    # calculate metrics for training & validation dataset\n",
    "    pred_labels_train = classify(X_train, (W, b))\n",
    "    pred_labels_val = classify(X_val, (W, b))\n",
    "    acc_train = f1_score(true_labels_train, pred_labels_train, average='weighted')\n",
    "    acc_val = f1_score(true_labels_val, pred_labels_val, average='weighted')\n",
    "    acc_train_hist.append(acc_train)\n",
    "    acc_val_hist.append(acc_val)\n",
    "\n",
    "    # calculate the chage in validation loss\n",
    "    change = numpy.abs((loss_val-old_loss_val)/old_loss_val)\n",
    "\n",
    "    # update the counter and old_val_loss\n",
    "    i += 1\n",
    "    old_loss_val = loss_val\n",
    "    \n",
    "    # update plot every 10 steps\n",
    "    if i%10 == 0:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        x = numpy.arange(i)\n",
    "        f, (ax1, ax2) = pyplot.subplots(1, 2, figsize=(12,6))\n",
    "\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.plot(x, loss_train_hist, label=\"training loss\")\n",
    "        ax1.plot(x, loss_val_hist, label=\"validation loss\")\n",
    "        ax1.set_title('Loss')\n",
    "        ax1.legend()\n",
    "\n",
    "        ax2.plot(x, acc_train_hist, label=\"training accuracy\")\n",
    "        ax2.plot(x, acc_val_hist, label=\"validation accuracy\")\n",
    "        ax2.set_title('Accuracy')\n",
    "        ax2.legend()\n",
    "\n",
    "        pyplot.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee8c4a",
   "metadata": {},
   "source": [
    "We can measure the final accuracy using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19490a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final accuracy\n",
    "pred_labels_test = classify(X_test, (W, b))\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(true_labels_test, pred_labels_test)\n",
    "fscore_weighted = f1_score(true_labels_test, pred_labels_test, average='weighted')\n",
    "\n",
    "print(f\"{precision = }\")\n",
    "print(f\"{recall    = }\")\n",
    "print(f\"{fscore    = }\")\n",
    "print(f\"{support   = }\")\n",
    "print(f\"{fscore_weighted = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275fbb1",
   "metadata": {},
   "source": [
    "Show the predicted sentiment for a few test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred_sentiment'] = list(map(lambda x : encoder.categories_[0][x], pred_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629ab2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=['clean_tweet']).iloc[::200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a08220",
   "metadata": {},
   "source": [
    "You can also test the model with new tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets = ['had a terrible experience',\n",
    "              'thank you A airlines',\n",
    "              'I felt sick during the flight',\n",
    "              'flight was delayed again',\n",
    "              'love flying with A airlines']\n",
    "\n",
    "new_clean_tweets = list(map(clean_tweet, new_tweets))\n",
    "X_new = vectorizer.transform(new_clean_tweets).astype('float').toarray()\n",
    "labels_new = list(map(lambda x : encoder.categories_[0][x], classify(X_new, (W,b))))\n",
    "\n",
    "for tweet, label in zip(new_tweets, labels_new):\n",
    "    print(tweet, ':' ,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0232d5e",
   "metadata": {},
   "source": [
    "## What we've learned\n",
    "\n",
    "- Text data preprocessing\n",
    "- Softmax regression\n",
    "- One-hot encoding\n",
    "- Learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3548b0",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Crowdflower, 2019. Kaggle. https://www.kaggle.com/crowdflower/twitter-airline-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7dc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell to load the notebook's style sheet, then ignore it\n",
    "from IPython.core.display import HTML\n",
    "css_file = '../style/custom.css'\n",
    "HTML(open(css_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6038b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
